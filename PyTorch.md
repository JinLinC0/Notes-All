# 深度学习

## 机器学习的基础





## 深度学习的发展

最早的深度学习基础从线性神经网络和多层感知机开始，到基于空间的卷积神经网络和基于时间的循环神经网络，后来又出现了`Attention`注意力机制

深度学习还需要学习优化算法（优化给出模型的网络结构），高性能的计算，并行算法

深度学习目前主要有两大领域：计算机视觉领域（目标检测，语义分割）；自然语言处理领域（词嵌入，`BERT`）



## `PyTorch`

## 基础语法

### 数据操作

#### 数据维度

N维数组是机器学习和神经网络的主要数据结构

- 0维（0-d）的数组叫做标量，一个类别
- 1维（1-d）的数组叫做向量，一个特征向量（样本抽象成一行数字）
- 2维（2-d）的数组叫做矩阵，一个样本（样本的特征矩阵）（每一行表示一个样本，每一列表示不同的特征）
- 3维（3-d）一般是一张`RGB`图片，宽、高和`RGB`三个通道
- 4维（4-d）一般表示一个`RGB`图片的批量（批量大小、宽、高和通道）
- 5维（5-d）一般表示视频批量（批量大小、小时、宽、高和通道）

#### 访问元素

访问在矩阵中元素的索引方法：

![image-20241126194715232](.\images\image-20241126194715232.png)

> ：表示访问这一行/列的所有元素
>
> 对子区域的访问，是左闭右开的（左边的索引包括，右边的索引不包括）
>
> ::3表示访问第0行到最后一行，并且以3行一跳访问

#### 张量实现相关

张量`tensor`表示一个数值组成的数组，这个数组可能有多个维度，具有一个轴的张量对应数学上的向量（`vector`）；具有两个轴的张量对应数学上的矩阵（`matrix`）；具有两个轴以上的张量没有特殊的数学名称

- 创建一个行向量：`x = torch.arange(3)`       得到：`tensor([0, 1, 2])`

- 查看这个张量的形状：`x.shape`      得到：`torch.Size([3])`   表示一个维度的向量，维度长维3

  在跑机器学习算法的时候，建议执行完每一步操作后，打印一下矩阵的维度看看，方便对结果正确性的考量

- 查看张量元素的总数：`x.numel()`    返回的永远是一个标量     得到3

- 要想改变一个张量的形状而不改变元素数量和元素值，可以调用`reshape`函数

  如果是一个长为12的向量，我们可以通过`X = x.reshape(3, 4)`，将其改为3行4列的矩阵，元素在每一行是连续的

  改变矩阵维度的另一种方法`view`

  ![image-20241017203739638](.\images\image-20241017203739638.png)

  > `view(16)`表示将矩阵拉成一行的向量，16表示一行中有16个元素
  >
  > `view(-1, 8)`表示第二个维度有8个元素，-1表示根据原始的矩阵和另一个维度取进行自动的当前维度的计算

  但是要注意以下的情况：通过`reshape`的情况生成的另一个张量，将这个张量进行改变后，会导致原先的张量也发生改变

  ![image-20241126214323727](.\images\image-20241126214323727.png)

- 创建全为0或全为1的矩阵：`torch.zeros()`/`torch.empty()`     `torch.ones()`

  ![image-20241126202002947](.\images\image-20241126202002947.png)

- 创建一个随机内容的矩阵：`torch.rand()`

- 创建指定内容的张量：

  ![image-20241126202446048](.\images\image-20241126202446048.png)

  在指定内容的时候，如果创建的张量中有一个元素指定为`x.0`，那么这个张量的所有元素都是浮点的类型，浮点类型在打印中的体现是在数字后面跟着一个点，如`0.`

  如果随机生成，我们可以采用以下的方式进行指定：

  `X = torch.arange(12, dtype=torch.float32).reshape((3, 4))`

#### 运算符

基本运算类型

![image-20241126203054619](.\images\image-20241126203054619.png)

> 张量的加法也可以写成`touch.add(x, y)`

我们还可以把多个张量连结在一起，端对端地叠起来形成一个更大的张量，通过`torch.cat()`来实现：

![image-20241126204608698](.\images\image-20241126204608698.png)

> `dim=0`表示在第0维进行合并，按行上面进行合并
>
> `dim=1`表示在第1维进行合并，按列上面进行合并

我们还可以对张量中所有的元素进行求和操作：`X.sum()`

#### 广播机制

在某些情况下，即使形状不同，我们仍然可以通过调用广播机制（`broadcasting mechanism`）来执行按元素操作，这种机制的工作方式如下：
1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；
2. 对生成的数组执行按元素操作。

![image-20241126205733244](.\images\image-20241126205733244.png)

由于a和b分别是3 × 1和1 × 2矩阵，如果让它们相加，它们的形状不匹配。我们将两个矩阵广播为一个更大的3 × 2矩阵，如下所示：矩阵a将复制列，矩阵b将复制行，然后再按元素相加

![image-20241126205748853](.\images\image-20241126205748853.png)

> 广播机制工作的前提是需要维度一样，比如相加的两部分都是数组
>
> 我们需要知道这个机制的存在，防止以后张量维度变化后出现的误操作（矩阵的维度不一样也是能进行运算的，而不会进行报错）

#### 内存机制

运行一些操作可能会导致为新结果分配内存

例如，如果我们用Y = X + Y，我们将取消引用Y指向的张量，指向新分配的内存处的张量（新的Y的地址和以前的不同，不是公用一个内存地址），因此内存比较大的张量不要进行过度的赋值

因此我们需要执行原地操作：

![image-20241126210919652](.\images\image-20241126210919652.png)

> Z[:] = X + Y 表示对Z中全部的元素进行一次改写，但是不会造成内存发生变化

如果在后续计算中没有重复使用X，我们也可以使用X[:] = X + Y或X += Y来减少操作的内存开销

![image-20241126211303035](.\images\image-20241126211303035.png)

我们可以通过`clone`的方法，将一个张量的一个副本分配给另一个张量，这样这两个张量就有不同的内存地址了，但是其内容是一样的：`B = A.clone()`

#### 数据转换

##### 与`NumPy`张量进行转换

将深度学习框架定义的张量转换为`NumPy`张量（`ndarray`）很容易，反之也同样容易。`torch`张量和`numpy`数
组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量

![image-20241126211732314](.\images\image-20241126211732314.png)

将`tensor`格式的数据转换成`numpy`中其他数据类型的格式，如一个数组：

![image-20241017204208769](.\images\image-20241017204208769.png)

> 通过`numpy`将`tensor`类型的数组进行格式的转换，转换为`numpy`所支持的格式，使后续可以进行交互的计算

将`numpy`数据类型的格式转换成`tensor`格式的数据：

![image-20241017205705355](.\images\image-20241017205705355.png)

总之：`numpy`格式的数据可以和`tensor`格式的数据进行互相转换和交互

要将大小为1的张量转换为`Python`标量，我们可以调用`item`函数或`Python`的内置函数：

![image-20241126211839714](.\images\image-20241126211839714.png)

#### 数据预处理

在`Python`中常用的数据分析工具中，我们通常使用`pandas`软件包。像庞大的`Python`生态系统中的许多其他扩展包一样，`pandas`可以与张量兼容

##### 创建`csv`文件

创建一个人工数据集，并存储在`CSV`（每一行是一个数据，使用逗号分隔值）文件

```py
import os

os.makedirs(os.path.join('..', 'data'), exist_ok=True)  # 创建了一个文件夹
# 创建了一个文件，文件名为house_tiny.csv
data_file = os.path.join('..', 'data', 'house_tiny.csv')  
with open(data_file, 'w') as f:
    f.write('NumRooms,Alley,Price\n') # 列名
    f.write('NA,Pave,127500\n') # 每行表示一个数据样本，NA表示未知的数NAN
    f.write('2,NA,106000\n')
    f.write('4,NA,178100\n')
    f.write('NA,NA,140000\n')
```

##### 读取`csv`文件

要从创建的`CSV`文件中加载原始数据集，我们导入`pandas`包并调用`read_csv`函数

```py
import pandas as pd

data_file = os.path.join('..', 'data', 'house_tiny.csv')  
data = pd.read_csv(data_file)
print(data)
```

![image-20241126212932631](.\images\image-20241126212932631.png)

#### 缺失值处理

为了处理缺失的数据，典型的方法包括插值法和删除法，其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值，一般都是使用插值法进行处理，丢弃整条包含单个元素缺失的数据太可惜了

```py
# inputs表示的是有缺失值的列，outputs表示的是没有缺失值的列
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
inputs = inputs.fillna(inputs.mean())
print(inputs)
```

![image-20241126213403584](.\images\image-20241126213403584.png)

> 将缺失值，全部填写为所有不是缺失值的平均值（`mean`）
>
> 对于`Alley`中的数据是字符串类型的，因此没有发生变化

![image-20241126213814392](.\images\image-20241126213814392.png)

现在`inputs`和`outputs`中的所有条目都是数值类型，它们可以转换为张量格式：

```py
import torch
X = torch.tensor(inputs.to_numpy(dtype=float))
y = torch.tensor(outputs.to_numpy(dtype=float))
X, y
```

![image-20241126213900989](.\images\image-20241126213900989.png)

***

### 线性代数相关

- 矩阵的转置：`X.T`

  对于对称矩阵而言，其转置等于自己：`X == X.T`

- 两个矩阵的按元素乘法（对应位置进行乘法）称为哈达玛积，数学符号为一个圈里面加一个点：`A * B`或者通过以下的方式：`torch.dot(A, B)`

- 一个标量和一个矩阵进行相加和相乘，是将这个标量值与矩阵的所有元素进行相加和相乘

- 对张量的所有元素进行求和：`X.sum()`  不管张量是什么形状的，求和后的结果永远是一个标量

  默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量，但是我们还可以指定张量沿哪一个轴来通过求和降低维度，这就是后续的降维操作

- 降维操作

- 对张量的所有元素进行求均值：`X.mean()`，等价于`X.sum() / X.numel()`

  同样的，也可以按照某个维度进行求均值`X.mean(axis=0)`

- 通过降维操作进行求和或者求均值，就将这个维度丢弃了，如果我们不想将这个维度丢弃，可以设置`keepdims=True`

  ![image-20241127204241130](.\images\image-20241127204241130.png)

- 矩阵和向量相乘：`torch.mv(A, x)`

  ![image-20241127204642705](.\images\image-20241127204642705.png)

- 矩阵和矩阵的乘积：`torch.mm(A, B)`

- 求向量的范数（`L2`范数）（长度）（向量元素平方和的平方根）：`torch.norm(u)`

- 求向量的`L1`范数（向量元素的绝对值之和）：`torch.abs(u).sum()`

- 求矩阵的F范数（矩阵元素的平方和的平方根）（将矩阵拉成一个向量，在做向量的范数）：`torch.norm(X)`

  

  

  

  



## 自动求导机制

前向传播理解起来比较容易，但是反向传播理解起来是比较困难的，在反向传播中，我们一般需要对每个参数进行求导（对矩阵w进行逐层的求导），我们对矩阵进行求导往往难度是比较大的，这就需要使用`PyTorch`中的自动求导机制，帮我们将反向传播全部计算好了，我们只需要将时间放在，怎么设计网络，怎么构建网络模型即可

![image-20241017210602890](.\images\image-20241017210602890.png)

> 其中`requires_grad=True`表示可以对当前指定的矩阵进行求导操作，我们一般在构建这个矩阵的时候，直接将可以求导的这个参数进行传入

```py
b = torch.randn(3, 4, requires_grad=True)
t = x + b
# 对t矩阵进行求和，理解时可以将y当作一个损失函数
y = t.sum()
y
```

![image-20241017211044740](.\images\image-20241017211044740.png)

```py
# 对y进行一个反向传播
y.backward()
```

对b进行一个求导操作：由于`t = x + b`，也可以直接看出b的导数都是1

![image-20241017211203637](.\images\image-20241017211203637.png)

![image-20241017211311577](.\images\image-20241017211311577.png)

> 当y在做一个反向传播的时候，凡是用到的那个参数，会自动的将所用到的参数的`requires_grad`属性设置为`True`

其他的例子：

![image-20241017211629779](.\images\image-20241017211629779.png)

![image-20241017211907929](.\images\image-20241017211907929.png)

![image-20241017212043568](.\images\image-20241017212043568.png)

> `is_leaf`表示是否为子叶节点

![image-20241017212256315](.\images\image-20241017212256315.png)

> `b.grad`每一次是1，上面因为执行的8次，所以变成了8